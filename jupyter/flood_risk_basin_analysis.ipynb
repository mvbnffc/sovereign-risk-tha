{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#### Notebook for analysing flood risk at the basin scale and for plotting figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "##### Load the basin level risk data and prepare for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_data = pd.read_csv(r\"D:\\projects\\sovereign-risk\\Thailand\\analysis\\flood\\risk_analysis\\risk_basin_zonal_sum.csv\")\n",
    "# Add columne for annual exceedance probability\n",
    "risk_data['AEP'] = 1 / risk_data['RP']\n",
    "# Add a column converting current prorection level into AEP\n",
    "risk_data['Pr_L_AEP'] = np.where(risk_data['Pr_L'] == 0, 0, 1 / risk_data['Pr_L']) # using numpy where avoids zero division errors\n",
    "#### Add row for each combination that sums residential and non-residential damages\n",
    "grouped = risk_data.groupby(['FID', 'GID_1', 'NAME', 'HB_L4', 'HB_L5', 'HB_L6', 'HB_L7', 'Pr_L', 'Pr_L_AEP', 'Add_Pr', 'New_Pr_L', 'epoch', 'adaptation_scenario', 'RP', 'AEP'], as_index=False)['damages'].sum()\n",
    "grouped['urban_class'] = 'Combined'  # Add a column for urban_class with value 'total'\n",
    "risk_data = pd.concat([risk_data, grouped], ignore_index=True).sort_values(by=['FID', 'GID_1', 'NAME', 'HB_L4', 'HB_L5', 'HB_L6', 'HB_L7', 'Pr_L', 'Pr_L_AEP', 'Add_Pr', 'New_Pr_L', 'epoch', 'adaptation_scenario', 'RP', 'AEP'])\n",
    "risk_data.reset_index(drop=True, inplace=True)\n",
    "risk_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "basin_level = 'HB_L4'\n",
    "epoch = \"Today\"\n",
    "adaptation_scenario = \"Baseline\"\n",
    "urban_class = \"Residential\"\n",
    "RP = 100\n",
    "filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['adaptation_scenario'] == adaptation_scenario) & (risk_data['urban_class'] == urban_class) & (risk_data['RP'] == RP)]\n",
    "grouped = filtered_risk_data.groupby('HB_L4')\n",
    "sum_damages_per_basin = grouped['damages'].sum()\n",
    "print(sum_damages_per_basin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "##### Define function for interpolation between RP damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to linearly interpolate between RP damages\n",
    "def interpolate_damages(sub_df, sim_aep):\n",
    "    known_aeps = sub_df['AEP'].values\n",
    "    known_damages = sub_df['damages'].values\n",
    "    # Interpolate based off simulated AEP\n",
    "    if sim_aep > 0.5: \n",
    "        return 0 # for RPs below 2 years we assume 0 damages\n",
    "    else:\n",
    "        return np.interp(sim_aep, known_aeps, known_damages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "##### Run a simulation specifying specific variables. Will plot figures and output key RPs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for simulation\n",
    "basin_level = 'HB_L6'\n",
    "epoch = \"Today\"\n",
    "adaptation_scenario = \"Baseline\"\n",
    "urban_class = \"Residential\"\n",
    "simulation_years = 1000\n",
    "rps = [2, 10, 50, 100, 1000]\n",
    "national_losses = []\n",
    "\n",
    "# filter the risk data based on the variable specifications above\n",
    "filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['adaptation_scenario'] == adaptation_scenario) & (risk_data['urban_class'] == urban_class)]\n",
    "# Group the risk data by basin ID and AEP\n",
    "group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "\n",
    "# Loop through years and simulate\n",
    "for _ in range(simulation_years):\n",
    "\n",
    "    # Calculate damages for each specified basin level based on simulated random number\n",
    "    basin_damages = group_risk_data.groupby(basin_level).apply(\n",
    "        lambda sub_df: interpolate_damages(sub_df, np.random.uniform(0, 1)) # simulate a random number between 0 and 1 for each basin\n",
    "    )\n",
    "    \n",
    "    # Sum damages for national scale\n",
    "    national_loss = basin_damages.sum()\n",
    "    national_losses.append(national_loss)\n",
    "\n",
    "    # Debug\n",
    "    if national_loss == 0:\n",
    "        print('National Loss is Zero')\n",
    "    \n",
    "#### Plot figures\n",
    "national_losses_sorted = np.sort(national_losses)[::-1] # Sort losses in descending order\n",
    "national_losses_sorted = national_losses_sorted/1000000000 # show it in billion\n",
    "N = len(national_losses_sorted) # How many data points?\n",
    "exceedance_probabilities = np.arange(1, N+1) / (N+1) # Calculate exceedance probabilities\n",
    "\n",
    "# Extract RP Losses\n",
    "def loss_at_rp(rp):\n",
    "    aep = 1 / rp  # Annual exceedance probability\n",
    "    # Approximate index in the sorted array\n",
    "    idx = int(aep * N) - 1\n",
    "    return national_losses_sorted[idx]\n",
    "\n",
    "# Plot the Loss Exceedance Probability Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(exceedance_probabilities, national_losses_sorted, marker='.', linestyle='-')\n",
    "# plt.xscale('log')\n",
    "plt.ylabel('Loss ($b)')\n",
    "plt.xlabel('Probability')\n",
    "plt.xlim(0, 1)\n",
    "plt.suptitle('Loss Exceedance Probability Curve')\n",
    "plt.title('Basin Level: %s, Epoch: %s, Adaptation Scenario: %s, Urban Class: %s' % (basin_level, epoch, adaptation_scenario, urban_class), fontsize=8)\n",
    "plt.grid(True, which='both', ls='--')\n",
    "\n",
    "# Inset for Return Period Losses\n",
    "rp_losses_text = \"\"  # Initialize an empty string to accumulate loss text\n",
    "for rp in rps:\n",
    "    loss = loss_at_rp(rp)\n",
    "    rp_losses_text += f\"{rp}-year RP Loss: US$b {loss:.2f} \\n\"\n",
    "# Average Annual Loss\n",
    "aal = national_losses_sorted.mean()\n",
    "rp_losses_text += f\"Average Annual Loss: US$b {aal:.2f}\"\n",
    "\n",
    "# Annotate on the plot\n",
    "plt.annotate(rp_losses_text, xy=(0.65, 0.8), xycoords='axes fraction', fontsize=10,\n",
    "             bbox=dict(boxstyle=\"square,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Run for Current Protection Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to linearly interpolate between RP damages (this time considering current protection levels)\n",
    "def interpolate_damages_pr(sub_df, sim_aep, basin_level):\n",
    "    # # Debug\n",
    "    # print(sub_df)\n",
    "    # First filter damages based of simulated AEP and existing protection level\n",
    "    sub_df.loc[sub_df['Pr_L_AEP'] < sim_aep, 'damages'] = 0\n",
    "    # Group by basin and AEP\n",
    "    group_sub = sub_df.groupby([basin_level, 'AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "    known_aeps = group_sub['AEP'].values\n",
    "    known_damages = group_sub['damages'].values\n",
    "    # Interpolate based off simulated AEP\n",
    "    if sim_aep > 0.5: \n",
    "        return 0 # for RPs below 2 years we assume 0 damages\n",
    "    else:\n",
    "        return np.interp(sim_aep, known_aeps, known_damages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's test baseline condition under current protection levels.\n",
    "\n",
    "# Set variables for simulation\n",
    "basin_level = 'HB_L7'\n",
    "epoch = \"Today\"\n",
    "adaptation_scenario = \"Baseline\"\n",
    "urban_class = \"Combined\"\n",
    "simulation_years = 1000\n",
    "rps = [10, 50, 100, 1000]\n",
    "national_losses = []\n",
    "\n",
    "# filter the risk data based on the variable specifications above\n",
    "filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['adaptation_scenario'] == adaptation_scenario) & (risk_data['urban_class'] == urban_class)]\n",
    "# Group the risk data by basin ID, AEP, and current protection level\n",
    "group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP', 'Pr_L_AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "\n",
    "# Loop through years and simulate\n",
    "for _ in range(simulation_years):\n",
    "\n",
    "    # Calculate damages for each specified basin level based on simulated random number\n",
    "    basin_damages = group_risk_data.groupby(basin_level).apply(\n",
    "        lambda sub_df: interpolate_damages_pr(sub_df, np.random.uniform(0, 1), basin_level) # simulate a random number between 0 and 1 for each basin\n",
    "    )\n",
    "    \n",
    "    # Sum damages for national scale\n",
    "    national_loss = basin_damages.sum()\n",
    "    national_losses.append(national_loss)\n",
    "\n",
    "#### Plot figures\n",
    "national_losses_sorted = np.sort(national_losses)[::-1] # Sort losses in descending order\n",
    "national_losses_sorted = national_losses_sorted/1000000000 # show it in billion\n",
    "N = len(national_losses_sorted) # How many data points?\n",
    "exceedance_probabilities = np.arange(1, N+1) / (N+1) # Calculate exceedance probabilities\n",
    "\n",
    "# Extract RP Losses\n",
    "def loss_at_rp(rp):\n",
    "    aep = 1 / rp  # Annual exceedance probability\n",
    "    # Approximate index in the sorted array\n",
    "    idx = int(aep * N) - 1\n",
    "    return national_losses_sorted[idx]\n",
    "\n",
    "# Plot the Loss Exceedance Probability Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(exceedance_probabilities, national_losses_sorted, marker='.', linestyle='-')\n",
    "# plt.xscale('log')\n",
    "plt.ylabel('Loss ($b)')\n",
    "plt.xlabel('Probability')\n",
    "plt.xlim(0, 0.8)\n",
    "plt.suptitle('Loss Exceedance Probability Curve')\n",
    "plt.title('Basin Level: %s, Epoch: %s, Adaptation Scenario: %s, Urban Class: %s' % (basin_level, epoch, adaptation_scenario, urban_class), fontsize=8)\n",
    "plt.grid(True, which='both', ls='--')\n",
    "\n",
    "# Inset for Return Period Losses\n",
    "rp_losses_text = \"\"  # Initialize an empty string to accumulate loss text\n",
    "for rp in rps:\n",
    "    loss = loss_at_rp(rp)\n",
    "    rp_losses_text += f\"{rp}-year RP Loss: US$b {loss:.2f} \\n\"\n",
    "# Average Annual Loss\n",
    "aal = national_losses_sorted.mean()\n",
    "rp_losses_text += f\"Average Annual Loss: US$b {aal:.2f}\"\n",
    "\n",
    "# Annotate on the plot\n",
    "plt.annotate(rp_losses_text, xy=(0.65, 0.8), xycoords='axes fraction', fontsize=10,\n",
    "             bbox=dict(boxstyle=\"square,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Run for Idealized Protection Levels 100 RP (no urban distinction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to linearly interpolate between RP damages\n",
    "def interpolate_damages_100(sub_df, sim_aep):\n",
    "    known_aeps = sub_df['AEP'].values\n",
    "    known_damages = sub_df['damages'].values\n",
    "    # Interpolate based off simulated AEP\n",
    "    if sim_aep > 0.01: \n",
    "        return 0 # for RPs below 2 years we assume 0 damages\n",
    "    else:\n",
    "        return np.interp(sim_aep, known_aeps, known_damages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for simulation\n",
    "basin_level = 'HB_L7'\n",
    "epoch = \"Today\"\n",
    "adaptation_scenario = \"Baseline\"\n",
    "urban_class = \"Combined\"\n",
    "simulation_years = 1000\n",
    "rps = [10, 50, 100, 1000]\n",
    "national_losses = []\n",
    "\n",
    "# filter the risk data based on the variable specifications above\n",
    "filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['adaptation_scenario'] == adaptation_scenario) & (risk_data['urban_class'] == urban_class)]\n",
    "# Group the risk data by basin ID and AEP\n",
    "group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "\n",
    "# Loop through years and simulate\n",
    "for _ in range(simulation_years):\n",
    "\n",
    "    # Calculate damages for each specified basin level based on simulated random number\n",
    "    basin_damages = group_risk_data.groupby(basin_level).apply(\n",
    "        lambda sub_df: interpolate_damages_100(sub_df, np.random.uniform(0, 1)) # simulate a random number between 0 and 1 for each basin\n",
    "    )\n",
    "    \n",
    "    # Sum damages for national scale\n",
    "    national_loss = basin_damages.sum()\n",
    "    national_losses.append(national_loss)\n",
    "    \n",
    "#### Plot figures\n",
    "national_losses_sorted = np.sort(national_losses)[::-1] # Sort losses in descending order\n",
    "national_losses_sorted = national_losses_sorted/1000000000 # show it in billion\n",
    "N = len(national_losses_sorted) # How many data points?\n",
    "exceedance_probabilities = np.arange(1, N+1) / (N+1) # Calculate exceedance probabilities\n",
    "\n",
    "# Extract RP Losses\n",
    "def loss_at_rp(rp):\n",
    "    aep = 1 / rp  # Annual exceedance probability\n",
    "    # Approximate index in the sorted array\n",
    "    idx = int(aep * N) - 1\n",
    "    return national_losses_sorted[idx]\n",
    "\n",
    "# Plot the Loss Exceedance Probability Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(exceedance_probabilities, national_losses_sorted, marker='.', linestyle='-')\n",
    "# plt.xscale('log')\n",
    "plt.ylabel('Loss ($b)')\n",
    "plt.xlabel('Probability')\n",
    "plt.xlim(0, 0.5)\n",
    "plt.suptitle('Loss Exceedance Probability Curve')\n",
    "plt.title('Basin Level: %s, Epoch: %s, Adaptation Scenario: %s, Urban Class: %s' % (basin_level, epoch, adaptation_scenario, urban_class), fontsize=8)\n",
    "plt.grid(True, which='both', ls='--')\n",
    "\n",
    "# Inset for Return Period Losses\n",
    "rp_losses_text = \"\"  # Initialize an empty string to accumulate loss text\n",
    "for rp in rps:\n",
    "    loss = loss_at_rp(rp)\n",
    "    rp_losses_text += f\"{rp}-year RP Loss: US$b {loss:.2f} \\n\"\n",
    "# Average Annual Loss\n",
    "aal = national_losses_sorted.mean()\n",
    "rp_losses_text += f\"Average Annual Loss: US$b {aal:.2f}\"\n",
    "\n",
    "# Annotate on the plot\n",
    "plt.annotate(rp_losses_text, xy=(0.65, 0.8), xycoords='axes fraction', fontsize=10,\n",
    "             bbox=dict(boxstyle=\"square,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Run for Idealized Protection Levels 100 RP (urban distinction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to linearly interpolate between RP damages\n",
    "def interpolate_damages_100_ub(sub_df, adaptation_scenario, sim_aep):\n",
    "    # Use baseline maps if AEP < 0.01\n",
    "    if sim_aep < 0.01:\n",
    "        sub_df = sub_df[sub_df['adaptation_scenario']=='Baseline']\n",
    "        known_aeps = sub_df['AEP'].values\n",
    "        known_damages = sub_df['damages'].values\n",
    "        return np.interp(sim_aep, known_aeps, known_damages)\n",
    "    elif sim_aep > 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        # interpolate urban protection as normal\n",
    "        sub_df = sub_df[sub_df['adaptation_scenario']==adaptation_scenario]\n",
    "        known_aeps = sub_df['AEP'].values\n",
    "        known_damages = sub_df['damages'].values\n",
    "        return np.interp(sim_aep, known_aeps, known_damages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's test baseline condition under current protection levels.\n",
    "\n",
    "# Set variables for simulation\n",
    "basin_level = 'HB_L7'\n",
    "epoch = \"Today\"\n",
    "adaptation_scenario = \"Urban_Protection_RP100\"\n",
    "urban_class = \"Combined\"\n",
    "simulation_years = 1000\n",
    "rps = [10, 50, 100, 1000]\n",
    "national_losses = []\n",
    "\n",
    "# # filter the risk data based on the variable specifications above\n",
    "# filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['adaptation_scenario'] == adaptation_scenario) & (risk_data['urban_class'] == urban_class)]\n",
    "# # Group the risk data by basin ID, AEP, and current protection level\n",
    "# group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP', 'Pr_L_AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "# group_risk_data\n",
    "\n",
    "# filter the risk data based on the variable specifications above\n",
    "filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['urban_class'] == urban_class)]\n",
    "# Group the risk data by basin ID, AEP, and current protection level\n",
    "group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP', 'adaptation_scenario']).agg({'damages': 'sum'}).reset_index()\n",
    "\n",
    "# Loop through years and simulate\n",
    "for _ in range(simulation_years):\n",
    "\n",
    "    # Calculate damages for each specified basin level based on simulated random number\n",
    "    basin_damages = group_risk_data.groupby(basin_level).apply(\n",
    "        lambda sub_df: interpolate_damages_100_ub(sub_df, adaptation_scenario, np.random.uniform(0, 1)) # simulate a random number between 0 and 1 for each basin\n",
    "    )\n",
    "    \n",
    "    # Sum damages for national scale\n",
    "    national_loss = basin_damages.sum()\n",
    "    national_losses.append(national_loss)\n",
    "    \n",
    "#### Plot figures\n",
    "national_losses_sorted = np.sort(national_losses)[::-1] # Sort losses in descending order\n",
    "national_losses_sorted = national_losses_sorted/1000000000 # show it in billion\n",
    "N = len(national_losses_sorted) # How many data points?\n",
    "exceedance_probabilities = np.arange(1, N+1) / (N+1) # Calculate exceedance probabilities\n",
    "\n",
    "# Extract RP Losses\n",
    "def loss_at_rp(rp):\n",
    "    aep = 1 / rp  # Annual exceedance probability\n",
    "    # Approximate index in the sorted array\n",
    "    idx = int(aep * N) - 1\n",
    "    return national_losses_sorted[idx]\n",
    "\n",
    "# Plot the Loss Exceedance Probability Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(exceedance_probabilities, national_losses_sorted, marker='.', linestyle='-')\n",
    "# plt.xscale('log')\n",
    "plt.ylabel('Loss ($b)')\n",
    "plt.xlabel('Probability')\n",
    "plt.xlim(0, 0.8)\n",
    "plt.suptitle('Loss Exceedance Probability Curve')\n",
    "plt.title('Basin Level: %s, Epoch: %s, Adaptation Scenario: %s, Urban Class: %s' % (basin_level, epoch, adaptation_scenario, urban_class), fontsize=8)\n",
    "plt.grid(True, which='both', ls='--')\n",
    "\n",
    "# Inset for Return Period Losses\n",
    "rp_losses_text = \"\"  # Initialize an empty string to accumulate loss text\n",
    "for rp in rps:\n",
    "    loss = loss_at_rp(rp)\n",
    "    rp_losses_text += f\"{rp}-year RP Loss: US$b {loss:.2f} \\n\"\n",
    "# Average Annual Loss\n",
    "aal = national_losses_sorted.mean()\n",
    "rp_losses_text += f\"Average Annual Loss: US$b {aal:.2f}\"\n",
    "\n",
    "# Annotate on the plot\n",
    "plt.annotate(rp_losses_text, xy=(0.65, 0.8), xycoords='axes fraction', fontsize=10,\n",
    "             bbox=dict(boxstyle=\"square,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### Run for DryProofing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's test baseline condition under current protection levels.\n",
    "\n",
    "# Set variables for simulation\n",
    "basin_level = 'HB_L7'\n",
    "epoch = \"Today\"\n",
    "adaptation_scenario = \"Dry_Proofing\"\n",
    "urban_class = \"Combined\"\n",
    "simulation_years = 1000\n",
    "rps = [10, 50, 100, 1000]\n",
    "national_losses = []\n",
    "\n",
    "# filter the risk data based on the variable specifications above\n",
    "filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['adaptation_scenario'] == adaptation_scenario) & (risk_data['urban_class'] == urban_class)]\n",
    "# Group the risk data by basin ID, AEP, and current protection level\n",
    "group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP', 'Pr_L_AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "group_risk_data\n",
    "\n",
    "# Loop through years and simulate\n",
    "for _ in range(simulation_years):\n",
    "\n",
    "    # Calculate damages for each specified basin level based on simulated random number\n",
    "    basin_damages = group_risk_data.groupby(basin_level).apply(\n",
    "        lambda sub_df: interpolate_damages_pr(sub_df, np.random.uniform(0, 1), basin_level) # simulate a random number between 0 and 1 for each basin\n",
    "    )\n",
    "    \n",
    "    # Sum damages for national scale\n",
    "    national_loss = basin_damages.sum()\n",
    "    national_losses.append(national_loss)\n",
    "    \n",
    "#### Plot figures\n",
    "national_losses_sorted = np.sort(national_losses)[::-1] # Sort losses in descending order\n",
    "national_losses_sorted = national_losses_sorted/1000000000 # show it in billion\n",
    "N = len(national_losses_sorted) # How many data points?\n",
    "exceedance_probabilities = np.arange(1, N+1) / (N+1) # Calculate exceedance probabilities\n",
    "\n",
    "# Extract RP Losses\n",
    "def loss_at_rp(rp):\n",
    "    aep = 1 / rp  # Annual exceedance probability\n",
    "    # Approximate index in the sorted array\n",
    "    idx = int(aep * N) - 1\n",
    "    return national_losses_sorted[idx]\n",
    "\n",
    "# Plot the Loss Exceedance Probability Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(exceedance_probabilities, national_losses_sorted, marker='.', linestyle='-')\n",
    "# plt.xscale('log')\n",
    "plt.ylabel('Loss ($b)')\n",
    "plt.xlabel('Probability')\n",
    "plt.xlim(0, 0.8)\n",
    "plt.suptitle('Loss Exceedance Probability Curve')\n",
    "plt.title('Basin Level: %s, Epoch: %s, Adaptation Scenario: %s, Urban Class: %s' % (basin_level, epoch, adaptation_scenario, urban_class), fontsize=8)\n",
    "plt.grid(True, which='both', ls='--')\n",
    "\n",
    "# Inset for Return Period Losses\n",
    "rp_losses_text = \"\"  # Initialize an empty string to accumulate loss text\n",
    "for rp in rps:\n",
    "    loss = loss_at_rp(rp)\n",
    "    rp_losses_text += f\"{rp}-year RP Loss: US$b {loss:.2f} \\n\"\n",
    "# Average Annual Loss\n",
    "aal = national_losses_sorted.mean()\n",
    "rp_losses_text += f\"Average Annual Loss: US$b {aal:.2f}\"\n",
    "\n",
    "# Annotate on the plot\n",
    "plt.annotate(rp_losses_text, xy=(0.65, 0.8), xycoords='axes fraction', fontsize=10,\n",
    "             bbox=dict(boxstyle=\"square,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Script to run Monte Carlo Simulations on all scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to map simulated AEPs to basin IDs\n",
    "# # Create function that will do interpolation on all possible scenarios\n",
    "\n",
    "# def interpolate_damages_all(sub_df, simulated_aeps, adaptation_scenario, year, protection_threshold, basin_level, baseline=False):\n",
    "    \n",
    "#     # Burn simulated aep onto sub_df\n",
    "#     def map_probability(row):\n",
    "#         # need to do this with a function\n",
    "#         basin_id = row[basin_level]\n",
    "#         if basin_id in simulated_aeps[basin_level]:\n",
    "#             # if BASINID found return probability for year\n",
    "#             return simulated_aeps[basin_level][basin_id][year]\n",
    "#         else:\n",
    "#             print('ERROR: no probability found')\n",
    "#             return pd.NA\n",
    "\n",
    "#     # Map simulated probabilities onto sub_df\n",
    "#     sub_df['sim_aep'] = sub_df.apply(map_probability, axis=1)\n",
    "#     # Extract simulated probability for interpolation\n",
    "#     sim_aep = max(sub_df['sim_aep'])\n",
    "\n",
    "#     # Here we will interpolate adaptation scenarios that consider the baseline protection level\n",
    "#     # These scenarios include: Urban_Protection_RP100, Baseline, Dry-Proofing, and Relocation,\n",
    "#     if baseline:\n",
    "#         # This adaptation scenario considers only urban areas are protected to the given RP. For the interpolation we use Baseline maps\n",
    "#         # for extreme probabilities. This ensures that when interpolating between 100 - 200 RP that we don't introduce additional protection\n",
    "#         # i.e. if there is a 101 year flood we assume protection is breached completely and risk is maxed out rather than interpolating between\n",
    "#         # 100 year protected risk and 200 year protected risk. This allows us to compare with the complete protection scenario. Also have now\n",
    "#         # included that it must consider baseline protection (otherwise it may lead to higher damages than baseline damages). \n",
    "#         if adaptation_scenario == \"Urban_Protection_RP100\":\n",
    "#                 # Use baseline maps if AEP < 0.01\n",
    "#             if sim_aep < 0.01:\n",
    "#                 sub_df = sub_df[sub_df['adaptation_scenario']=='Baseline']\n",
    "#                 known_aeps = sub_df['AEP'].values\n",
    "#                 known_damages = sub_df['damages'].values\n",
    "#                 return np.interp(sim_aep, known_aeps, known_damages)\n",
    "#             elif sim_aep > protection_threshold:\n",
    "#                 return 0\n",
    "#             else:\n",
    "#                 sub_df = sub_df[sub_df['adaptation_scenario']==adaptation_scenario]\n",
    "#                 sub_df['damages'] = np.where(sub_df['sim_aep'] > sub_df['Pr_L_AEP'], 0, sub_df['damages'])\n",
    "#                  # Group by basin and AEP\n",
    "#                 group_sub = sub_df.groupby([basin_level, 'AEP', 'sim_aep']).agg({'damages': 'sum'}).reset_index()\n",
    "#                 known_aeps = group_sub['AEP'].values\n",
    "#                 known_damages = group_sub['damages'].values\n",
    "#                 return np.interp(sim_aep, known_aeps, known_damages)\n",
    "        \n",
    "#         sub_df['damages'] = np.where(sub_df['sim_aep'] > sub_df['Pr_L_AEP'], 0, sub_df['damages'])\n",
    "#         # Group by basin and AEP\n",
    "#         group_sub = sub_df.groupby([basin_level, 'AEP', 'sim_aep']).agg({'damages': 'sum'}).reset_index()\n",
    "#         known_aeps = group_sub['AEP'].values\n",
    "#         known_damages = group_sub['damages'].values\n",
    "        \n",
    "#         # Interpolate based off simulated AEP\n",
    "#         if sim_aep > protection_threshold: \n",
    "#             return 0 # for RPs below specified protection threshold return 0 damage.\n",
    "#         else:\n",
    "#             return np.interp(sim_aep, known_aeps, known_damages)\n",
    "\n",
    "#     # All other adaptation scenarios do not need to consider baseline protection levels\n",
    "#     else:    \n",
    "#         # Complete urban protection\n",
    "#         known_aeps = sub_df['AEP'].values\n",
    "#         known_damages = sub_df['damages'].values\n",
    "\n",
    "#         # Interpolate based off simulated AEP\n",
    "#         if sim_aep > protection_threshold: \n",
    "#             return 0 # for RPs below specified protection threshold return 0 damage.\n",
    "#         else:\n",
    "#             return np.interp(sim_aep, known_aeps, known_damages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map simulated AEPs to basin IDs\n",
    "# Create function that will do interpolation on all possible scenarios\n",
    "\n",
    "def interpolate_damages_all(sub_df, simulated_aeps, adaptation_scenario, year, protection_threshold, basin_level):\n",
    "    \n",
    "    # Burn simulated aep onto sub_df\n",
    "    def map_probability(row):\n",
    "        # need to do this with a function\n",
    "        basin_id = row[basin_level]\n",
    "        if basin_id in simulated_aeps[basin_level]:\n",
    "            # if BASINID found return probability for year\n",
    "            return simulated_aeps[basin_level][basin_id][year]\n",
    "        else:\n",
    "            print('ERROR: no probability found')\n",
    "            return pd.NA\n",
    "\n",
    "    # Map simulated probabilities onto sub_df\n",
    "    sub_df['sim_aep'] = sub_df.apply(map_probability, axis=1)\n",
    "    # Extract simulated probability for interpolation\n",
    "    sim_aep = max(sub_df['sim_aep'])\n",
    "    \n",
    "    # This adaptation scenario considers only urban areas are protected to the given RP. For the interpolation we use Baseline maps\n",
    "    # for extreme probabilities. This ensures that when interpolating between 100 - 200 RP that we don't introduce additional protection\n",
    "    # i.e. if there is a 101 year flood we assume protection is breached completely and risk is maxed out rather than interpolating between\n",
    "    # 100 year protected risk and 200 year protected risk. This allows us to compare with the complete protection scenario. Also have now\n",
    "    # included that it must consider baseline protection (otherwise it may lead to higher damages than baseline damages). \n",
    "    if adaptation_scenario == \"Urban_Protection_RP100\":\n",
    "            # Use baseline maps if AEP < 0.01\n",
    "        if sim_aep < 0.01:\n",
    "            sub_df = sub_df[sub_df['adaptation_scenario']=='Baseline']\n",
    "            sub_df['damages'] = np.where(sub_df['sim_aep'] > sub_df['Pr_L_AEP'], 0, sub_df['damages'])\n",
    "            # Group by basin and AEP\n",
    "            group_sub = sub_df.groupby([basin_level, 'AEP', 'sim_aep']).agg({'damages': 'sum'}).reset_index()\n",
    "            known_aeps = group_sub['AEP'].values\n",
    "            known_damages = group_sub['damages'].values\n",
    "            return np.interp(sim_aep, known_aeps, known_damages)\n",
    "        elif sim_aep > protection_threshold:\n",
    "            return 0\n",
    "        else:\n",
    "            sub_df = sub_df[sub_df['adaptation_scenario']==adaptation_scenario]\n",
    "            sub_df['damages'] = np.where(sub_df['sim_aep'] > sub_df['Pr_L_AEP'], 0, sub_df['damages'])\n",
    "             # Group by basin and AEP\n",
    "            group_sub = sub_df.groupby([basin_level, 'AEP', 'sim_aep']).agg({'damages': 'sum'}).reset_index()\n",
    "            known_aeps = group_sub['AEP'].values\n",
    "            known_damages = group_sub['damages'].values\n",
    "            return np.interp(sim_aep, known_aeps, known_damages)\n",
    "    \n",
    "    sub_df['damages'] = np.where(sub_df['sim_aep'] > sub_df['Pr_L_AEP'], 0, sub_df['damages'])\n",
    "    # Group by basin and AEP\n",
    "    group_sub = sub_df.groupby([basin_level, 'AEP', 'sim_aep']).agg({'damages': 'sum'}).reset_index()\n",
    "    known_aeps = group_sub['AEP'].values\n",
    "    known_damages = group_sub['damages'].values\n",
    "    \n",
    "    # Interpolate based off simulated AEP\n",
    "    if sim_aep > protection_threshold: \n",
    "        return 0 # for RPs below specified protection threshold return 0 damage.\n",
    "    else:\n",
    "        return np.interp(sim_aep, known_aeps, known_damages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for simulation\n",
    "# Set all possible variable information\n",
    "simulation_years = 1000\n",
    "# basin_levels = ['HB_L4', 'HB_L5', 'HB_L6', 'HB_L7']\n",
    "basin_levels = ['HB_L7']\n",
    "epochs = ['Today']\n",
    "# epochs = ['Today', 'Future_High_Emission', 'Future_Low_Emission']\n",
    "# adaptation_scenarios = ['Baseline']\n",
    "adaptation_scenarios = ['Baseline', 'Dry_Proofing', 'Urban_Protection_RP100', 'Protection_RP100', 'Relocation']\n",
    "# urban_classes = ['Residential', 'Non-Residential', 'Combined']\n",
    "urban_classes = ['Combined']\n",
    "\n",
    "\n",
    "# Step 1: Presimulate random numbers for Monte Carlo simulation\n",
    "simulated_aeps = {}\n",
    "for basin_level in basin_levels:\n",
    "    basin_ids = risk_data[basin_level].unique()\n",
    "    simulated_aeps[basin_level] = {basin_id: np.random.uniform(0, 1, simulation_years) for basin_id in basin_ids}\n",
    "    \n",
    "# Step 2: Loop through all variable options and calculate losses\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "i = 0\n",
    "\n",
    "for basin_level in basin_levels:\n",
    "    for epoch in epochs:\n",
    "        for adaptation_scenario in adaptation_scenarios:\n",
    "            for urban_class in urban_classes:\n",
    "\n",
    "                # # Debug\n",
    "                # if epoch == \"Today\" and adaptation_scenario != \"Baseline\":\n",
    "                #     continue\n",
    "                # if adaptation_scenario != \"Baseline\" and epoch != \"Future_High_Emission\":\n",
    "                #     continue\n",
    "                \n",
    "                if i % 1 == 0:\n",
    "                    print('working on', epoch, adaptation_scenario)\n",
    "                i += 1\n",
    "                # Results list\n",
    "                national_losses = []\n",
    "                # Filter the risk data based on the variables specified in the loop\n",
    "                if adaptation_scenario == \"Protection_RP100\":\n",
    "                    # Doesn't have it's own column... user baseline\n",
    "                    filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['adaptation_scenario'] == \"Baseline\") & (risk_data['urban_class'] == urban_class)]\n",
    "                    # Don't need current protection levels if we are assuming 100 year protection everywhere\n",
    "                    group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP', 'Pr_L_AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "                elif adaptation_scenario == \"Urban_Protection_RP100\":\n",
    "                    # Going to send multiple different adaptation scenarios to the function. Because we pull from baseline maps for extreme risk\n",
    "                    filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['urban_class'] == urban_class)]\n",
    "                    # Group the risk data by basin ID, AEP, and current protection level\n",
    "                    group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP', 'adaptation_scenario', 'Pr_L_AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "                else:\n",
    "                    filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['adaptation_scenario'] == adaptation_scenario) & (risk_data['urban_class'] == urban_class)]\n",
    "                    group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP', 'Pr_L_AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "\n",
    "                # Loop through years\n",
    "                for year in range(simulation_years):\n",
    "\n",
    "                    # Calculate damages for all basins with specific variable specifications\n",
    "                    if adaptation_scenario == \"Protection_RP100\":\n",
    "                        # Assume everywhere has 100 year protection\n",
    "                        basin_damages = group_risk_data.groupby(basin_level).apply(\n",
    "                            lambda sub_df: interpolate_damages_all(sub_df, simulated_aeps, adaptation_scenario, year, 0.01, basin_level))\n",
    "                    elif adaptation_scenario == \"Urban_Protection_RP100\":\n",
    "                        basin_damages = group_risk_data.groupby(basin_level).apply(\n",
    "                            lambda sub_df: interpolate_damages_all(sub_df, simulated_aeps, adaptation_scenario, year, 0.5, basin_level) \n",
    "                        )\n",
    "                    else:\n",
    "                        basin_damages = group_risk_data.groupby(basin_level).apply(\n",
    "                            lambda sub_df: interpolate_damages_all(sub_df, simulated_aeps, adaptation_scenario, year, 0.5, basin_level))\n",
    "                    \n",
    "                    national_loss = basin_damages.sum()\n",
    "                    national_losses.append(national_loss)\n",
    "\n",
    "                results[\"{}_{}_{}_{}\".format(basin_level, epoch, adaptation_scenario, urban_class)] = national_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set variables for simulation\n",
    "# # Set all possible variable information\n",
    "# simulation_years = 10\n",
    "# # basin_levels = ['HB_L4', 'HB_L5', 'HB_L6', 'HB_L7']\n",
    "# basin_levels = ['HB_L7']\n",
    "# # epochs = ['Today']\n",
    "# epochs = ['Today', 'Future_High_Emission', 'Future_Low_Emission']\n",
    "# adaptation_scenarios = ['Baseline', 'Dry_Proofing', 'Urban_Protection_RP100', 'Protection_RP100', 'Relocation']\n",
    "# # urban_classes = ['Residential', 'Non-Residential', 'Combined']\n",
    "# urban_classes = ['Combined']\n",
    "\n",
    "\n",
    "# # Step 1: Presimulate random numbers for Monte Carlo simulation\n",
    "# simulated_aeps = {}\n",
    "# for basin_level in basin_levels:\n",
    "#     basin_ids = risk_data[basin_level].unique()\n",
    "#     simulated_aeps[basin_level] = {basin_id: np.random.uniform(0, 1, simulation_years) for basin_id in basin_ids}\n",
    "    \n",
    "# # Step 2: Loop through all variable options and calculate losses\n",
    "# # Results dictionary\n",
    "# results = {}\n",
    "\n",
    "# i = 0\n",
    "\n",
    "# for basin_level in basin_levels:\n",
    "#     for epoch in epochs:\n",
    "#         for adaptation_scenario in adaptation_scenarios:\n",
    "#             for urban_class in urban_classes:\n",
    "#                 if i % 1 == 0:\n",
    "#                     print('working on', epoch, adaptation_scenario)\n",
    "#                 i += 1\n",
    "#                 # Results list\n",
    "#                 national_losses = []\n",
    "#                 # Filter the risk data based on the variables specified in the loop\n",
    "#                 if adaptation_scenario == \"Protection_RP100\":\n",
    "#                     # Doesn't have it's own column... user baseline\n",
    "#                     filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['adaptation_scenario'] == \"Baseline\") & (risk_data['urban_class'] == urban_class)]\n",
    "#                     # Don't need current protection levels if we are assuming 100 year protection everywhere\n",
    "#                     group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "#                 elif adaptation_scenario == \"Urban_Protection_RP100\":\n",
    "#                     # Going to send multiple different adaptation scenarios to the function. Because we pull from baseline maps for extreme risk\n",
    "#                     filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['urban_class'] == urban_class)]\n",
    "#                     # Group the risk data by basin ID, AEP, and current protection level\n",
    "#                     group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP', 'adaptation_scenario', 'Pr_L_AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "#                 else:\n",
    "#                     filtered_risk_data = risk_data[(risk_data['epoch'] == epoch) & (risk_data['adaptation_scenario'] == adaptation_scenario) & (risk_data['urban_class'] == urban_class)]\n",
    "#                     group_risk_data = filtered_risk_data.groupby([basin_level, 'AEP', 'Pr_L_AEP']).agg({'damages': 'sum'}).reset_index()\n",
    "\n",
    "#                 # Loop through years\n",
    "#                 for year in range(simulation_years):\n",
    "\n",
    "#                     # Calculate damages for all basins with specific variable specifications\n",
    "#                     if adaptation_scenario == \"Protection_RP100\":\n",
    "#                         # Assume everywhere has 100 year protection\n",
    "#                         basin_damages = group_risk_data.groupby(basin_level).apply(\n",
    "#                             lambda sub_df: interpolate_damages_all(sub_df, simulated_aeps, adaptation_scenario, year, 0.01, basin_level))\n",
    "#                     elif adaptation_scenario == \"Urban_Protection_RP100\":\n",
    "#                         basin_damages = group_risk_data.groupby(basin_level).apply(\n",
    "#                             lambda sub_df: interpolate_damages_all(sub_df, simulated_aeps, adaptation_scenario, year, 0.5, basin_level, baseline=True) \n",
    "#                         )\n",
    "#                     else:\n",
    "#                         basin_damages = group_risk_data.groupby(basin_level).apply(\n",
    "#                             lambda sub_df: interpolate_damages_all(sub_df, simulated_aeps, adaptation_scenario, year, 0.5, basin_level, baseline=True))\n",
    "                    \n",
    "#                     national_loss = basin_damages.sum()\n",
    "#                     national_losses.append(national_loss)\n",
    "\n",
    "#                 results[\"{}_{}_{}_{}\".format(basin_level, epoch, adaptation_scenario, urban_class)] = national_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debug\n",
    "# print(np.sort(results['HB_L7_Future_High_Emission_Protection_RP100_Combined'][::-1]))\n",
    "# print(np.sort(results['HB_L7_Future_High_Emission_Urban_Protection_RP100_Combined'][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this dictionry so we don't have to run it again\n",
    "import pickle\n",
    "\n",
    "# Saving the dictionary to a file using pickle\n",
    "with open(r\"D:\\projects\\sovereign-risk\\Thailand\\analysis\\flood\\risk_analysis\\simulation_10000_results.pkl\", 'wb') as pickle_file:\n",
    "    pickle.dump(results, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### PLOT THIS BABY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate exceedance probabilities\n",
    "def calculate_exceedance_probabilities(losses):\n",
    "    sorted_losses = sorted(losses, reverse=True)\n",
    "    N = len(sorted_losses)\n",
    "    exceedance_probabilities = [(i+1) / (N+1) for i in range(N)]\n",
    "    return exceedance_probabilities, sorted_losses\n",
    "\n",
    "def calculate_rp_and_aal(losses):\n",
    "    # Sort losses in descending order\n",
    "    sorted_losses = sorted(losses, reverse=True)\n",
    "    N = len(sorted_losses)\n",
    "    \n",
    "    # Calculate exceedance probabilities\n",
    "    exceedance_probabilities = [(i+1) / (N+1) for i in range(N)]\n",
    "    \n",
    "    # Find the loss corresponding to the 100-year return period (RP = 100 years)\n",
    "    rp_10_index = np.searchsorted(exceedance_probabilities, 0.1, side='right') - 1\n",
    "    rp_10_loss = sorted_losses[rp_10_index] if rp_10_index < N else None\n",
    "    rp_50_index = np.searchsorted(exceedance_probabilities, 0.05, side='right') - 1\n",
    "    rp_50_loss = sorted_losses[rp_50_index] if rp_50_index < N else None\n",
    "    rp_100_index = np.searchsorted(exceedance_probabilities, 0.01, side='right') - 1\n",
    "    rp_100_loss = sorted_losses[rp_100_index] if rp_100_index < N else None\n",
    "    rp_200_index = np.searchsorted(exceedance_probabilities, 0.005, side='right') - 1\n",
    "    rp_200_loss = sorted_losses[rp_200_index] if rp_200_index < N else None\n",
    "    rp_500_index = np.searchsorted(exceedance_probabilities, 0.002, side='right') - 1\n",
    "    rp_500_loss = sorted_losses[rp_500_index] if rp_500_index < N else None\n",
    "    rp_1000_index = np.searchsorted(exceedance_probabilities, 0.001, side='right') - 1\n",
    "    rp_1000_loss = sorted_losses[rp_1000_index] if rp_1000_index < N else None\n",
    "    \n",
    "    # Calculate average annual loss (AAL)\n",
    "    aal = np.mean(losses)\n",
    "    \n",
    "    return rp_10_loss, rp_50_loss, rp_100_loss, rp_200_loss, rp_500_loss, rp_1000_loss, aal\n",
    "    \n",
    "\n",
    "# Example plotting function\n",
    "def plot_loss_probability_curves(results, scenarios_to_plot):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    RP_and_AAL = {} # dictioinary to save RP100 and AAL for printing \n",
    "    \n",
    "    for scenario in scenarios_to_plot:\n",
    "        if scenario in results:\n",
    "            losses = results[scenario]\n",
    "            losses = [i/1000000000 for i in losses]\n",
    "            rp_10, rp_50, rp_100, rp_200, rp_500, rp_1000, aal = calculate_rp_and_aal(losses)\n",
    "            RP_and_AAL[scenario] = [rp_10, rp_50, rp_100, rp_200, rp_500, rp_1000, aal]\n",
    "            exceedance_probabilities, sorted_losses = calculate_exceedance_probabilities(losses)\n",
    "            label = scenario_labels.get(scenario, scenario)  # Use custom label if provided, else use scenario name\n",
    "            plt.plot(exceedance_probabilities, sorted_losses, label=label)\n",
    "    \n",
    "    plt.xlabel('Probability')\n",
    "    plt.ylabel('Losses (US$b)')\n",
    "    plt.xlim(0, 0.5)\n",
    "    plt.title('Loss-Probability Curves')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', ls='--')\n",
    "    # plt.yscale('log')  # Optional: Log scale for better visualization of wide-ranging data\n",
    "    plt.show()\n",
    "\n",
    "    # Print RP and AAL for each scenario\n",
    "    for scenario, list in RP_and_AAL.items():\n",
    "        label = scenario_labels.get(scenario, scenario)  # Use custom label if provided\n",
    "        print(f\"{label}\")\n",
    "        print(f\"10-Year RP Loss = {list[0]:.2f} Billion\")\n",
    "        print(f\"50-Year RP Loss = {list[1]:.2f} Billion\")\n",
    "        print(f\"100-Year RP Loss = {list[2]:.2f} Billion\")\n",
    "        print(f\"200-Year RP Loss = {list[3]:.2f} Billion\")\n",
    "        print(f\"500-Year RP Loss = {list[4]:.2f} Billion\")\n",
    "        print(f\"1000-Year RP Loss = {list[5]:.2f} Billion\")\n",
    "        print(f\"AAL = {list[-1]:.2f} Billion\")\n",
    "\n",
    "# Specify the scenarios you want to plot\n",
    "# scenarios_to_plot = ['HB_L7_Future_High_Emission_Baseline_Combined', 'HB_L7_Future_High_Emission_Protection_RP100_Combined', \n",
    "#                      'HB_L7_Future_High_Emission_Urban_Protection_RP100_Combined', 'HB_L7_Future_High_Emission_Dry_Proofing_Combined',\n",
    "#                     'HB_L7_Future_High_Emission_Relocation_Combined']  # Add more as needed\n",
    "\n",
    "scenarios_to_plot = ['HB_L7_Today_Baseline_Combined', 'HB_L7_Today_Protection_RP100_Combined',\n",
    "                     'HB_L7_Today_Urban_Protection_RP100_Combined','HB_L7_Today_Dry_Proofing_Combined',\n",
    "                    'HB_L7_Today_Relocation_Combined']\n",
    "\n",
    "scenario_labels = {'HB_L7_Today_Baseline_Combined': 'Scenario 1',\n",
    "                  'HB_L7_Today_Protection_RP100_Combined': 'Scenario 2',\n",
    "                  'HB_L7_Today_Urban_Protection_RP100_Combined': 'Scenario 3',\n",
    "                  'HB_L7_Today_Dry_Proofing_Combined': 'Scenario 4',\n",
    "                  'HB_L7_Today_Relocation_Combined': 'Scenario 5'}\n",
    "\n",
    "\n",
    "# scenario_labels = {'HB_L7_Future_High_Emission_Baseline_Combined': 'Scenario 1: Baseline',\n",
    "#                   'HB_L7_Future_High_Emission_Protection_RP100_Combined': 'Scenario 2: 100-year Protection Everywhere',\n",
    "#                    'HB_L7_Future_High_Emission_Urban_Protection_RP100_Combined': 'Scenario 3: 100-year Protection in Urbanized Areas',\n",
    "#                   'HB_L7_Future_High_Emission_Dry_Proofing_Combined': 'Scenario 4: Dry Proofing of Buildings',\n",
    "#                   'HB_L7_Future_High_Emission_Relocation_Combined': 'Scenario 5: Relocation of Buildings'}\n",
    "\n",
    "# Plotting\n",
    "plot_loss_probability_curves(results, scenarios_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sort(results['HB_L7_Today_Baseline_Combined'][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sovereign-risk",
   "language": "python",
   "name": "sovereign-risk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
